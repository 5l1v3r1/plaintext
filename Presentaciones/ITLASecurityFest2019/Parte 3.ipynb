{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Entrenar la red neuronal para reconocer letras\n",
    "\n",
    "Luego de que tenemos las imagenes listas, lo que nos resta es entrenar nuestra red neuronal para que pueda aprender cada una de las 32 letras/números posibles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import os.path\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten, Dense\n",
    "from helpers import resize_to_fit\n",
    "\n",
    "# Probar el modelo\n",
    "from keras.models import load_model\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "LETTER_IMAGES_FOLDER = \"extracted_letter_images\"\n",
    "MODEL_FILENAME = \"captcha_model.hdf5\"\n",
    "MODEL_LABELS_FILENAME = \"model_labels.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializar los datos y las etiquetas\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Revisar cada imagen de entrada\n",
    "for image_file in paths.list_images(LETTER_IMAGES_FOLDER):    \n",
    "    # Cargue la imagen y conviértala a escala de grises\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Cambiar el tamaño de la letra para que quepa en un cuadro de 20x20 píxeles\n",
    "    image = resize_to_fit(image, 20, 20)\n",
    "    #print(\"Imagen Ampliada de 2 dimensiones: \" + str(image.shape))\n",
    "    \n",
    "    # Agregue una tercera dimensión de canal a la imagen para hacer feliz a Keras\n",
    "    image = np.expand_dims(image, axis=2)\n",
    "    #print(\"Image 3 channel dimension: \" + str(image.shape))\n",
    "        \n",
    "    # Tome el nombre de la letra en función de la carpeta en la que estaba\n",
    "    label = image_file.split(os.path.sep)[-2]\n",
    "\n",
    "    # Agregue la imagen de la letra y su etiqueta a nuestros datos de entrenamiento\n",
    "    data.append(image)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las imagenes son representadas en arreglos, numeros de 0 al 255. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data: \" + str(data[23323]))\n",
    "print(\"Labels: \" + str(labels[23323]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformaremos la representación del arreglo en una representación decimal de 0 a 1 para mejorar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(24/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escala las intensidades de píxeles sin procesar al rango [0, 1] (esto mejora el entrenamiento)\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data: \" + str(data[23323]))\n",
    "print(\"Labels: \" + str(labels[23323]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos los datasets de entrenamientos listos, las imagenes y el resultado, basicamente podemos asociar que la posición \n",
    "23323 corresponde a la letra M.\n",
    "\n",
    "Utilizaremos **X_train** y **X_test** como los conjuntos de datos con lás **imágenes de entrenamiento y validación respectivamente**, mientras que **Y_train** y **Y_test** son los datasets con **las etiquetas**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dividir los datos de entrenamiento en trenes y conjuntos de pruebas separados\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(data, labels, test_size=0.25, random_state=0)\n",
    "\n",
    "# Convierta las etiquetas (letras) en codificaciones únicas con las que Keras puede trabajar\n",
    "lb = LabelBinarizer().fit(Y_train)\n",
    "Y_train = lb.transform(Y_train)\n",
    "Y_test = lb.transform(Y_test)\n",
    "\n",
    "# Tamaño de la data\n",
    "print(\"Tamaño de la data: \" + str(len(data)))\n",
    "\n",
    "# Tamaño de data de entrenamiento\n",
    "print(\"Tamaño de data de entrenamiento: \" + str(len(Y_train)))\n",
    "\n",
    "# Representación binaria del resultado\n",
    "print(Y_train[23])\n",
    "\n",
    "# Quitar la dimensión que habíamos puesto para imprimir la imagen\n",
    "result = X_train[23][:, :, 0]\n",
    "\n",
    "print(result.shape)\n",
    "plt.imshow(result, cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La palabra **convolución** suena como un término elegante y complicado, pero en realidad no lo es. De hecho, si alguna vez ha trabajado con diseño gráfico, procesamiento de imágenes u OpenCV antes, ¡ya ha aplicado convoluciones, lo sepas o no!\n",
    "\n",
    "¿Alguna vez has aplicado desenfoque o suavizado? Sí, eso es una convolución.\n",
    "\n",
    "¿Qué pasa con la detección de bordes? Sí, convolución.\n",
    "\n",
    "¿Has abierto Photoshop o GIMP para enfocar una imagen? Lo has adivinado: convolución.\n",
    "\n",
    "Las convoluciones son uno de los componentes básicos más críticos y fundamentales en la visión por computadora y el procesamiento de imágenes.\n",
    "\n",
    "https://skymind.ai/wiki/convolutional-network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolución y pooling\n",
    "\n",
    "En el ejemplo anterior sobre los dígitos escritos a mano, usamos parches de imagen de 8×8 píxeles para entrenar un auto-codificador. La pregunta es, ¿por qué no introducir las imágenes completas?\n",
    "\n",
    "Cuanto mayor es la entrada del auto-codificador, más pesos hay que entrenar, y más lento es todo el proceso de entrenamiento. Si tenemos imágenes de 1000×1000 pixeles, y utilizamos 1000 neuronas en la capa oculta, necesitaríamos entrenar 2000 millones de pesos, mientras que si utilizamos parches de 8×8 y utilizamos 100 neuronas en la capa oculta, entrenamos sólo 12800 pesos.\n",
    "Si usamos imágenes enteras, para el auto-codificador una imagen que tenga un rostro centrado, y otra que tenga el mismo rostro ligeramente desplazado hacia un lado, son completamente diferentes.\n",
    "Especialmente con el fin de resolver el segundo punto, se puede utilizar una técnica conocida como convolución, y que está basada en cómo se estructuran realmente las neuronas en nuestro sistema visual.\n",
    "\n",
    "La idea de base es, ¿qué más da dónde aparezca un círculo? Un círculo sigue siendo un círculo aunque lo desplacemos.\n",
    "\n",
    "Por eso, podemos entrenar un auto-codificador con parches de imagen, y luego desplazar el codificador por toda la imagen, como si fuese un escáner, buscando características. Este proceso transforma la matriz de píxeles en otra matriz de características (listas de números) producidas por el codificador. Es esencialmente la misma imagen, pero cada pixel es mucho más rico en información, y contiene información de la región en que se encuentra el pixel, no sólo del pixel aislado.\n",
    "\n",
    "![title](img/convolution.png)\n",
    "\n",
    "El siguiente paso, llamado pooling, consiste en agrupar las características (listas de números) de varias coordinadas contiguas de la imagen, con alguna función de agrupación (la media, o el máximo). Esta etapa reduce la resolución de la imagen. A continuación podemos continuar haciendo convolución y pooling hasta que nos quede una imagen de 1×1 pixeles con muchísima información, o podemos incluir auto-codificadores intermedios que procesen los datos para buscar características de más alto nivel.\n",
    "\n",
    "![title](img/pooling.png)\n",
    "\n",
    "En una sola etapa de convolución y pooling, obtenemos una imagen de menos resolución, y que en cada píxel nos cuenta la siguiente historia: “en esta región de la imagen hay un círculo y una línea”. No nos dice exactamente dónde estaba el círculo en la matriz con la resolución original. Si ahora acoplamos otro auto-codificador, alguna neurona puede aprender a activarse siempre que reciba esta información agregada acerca de un círculo y una línea, y cuando apliquemos todo el sistema a nuestros números, esa neurona se activará cuando la imagen tenga dibujado el número nueve, por ejemplo.\n",
    "\n",
    "https://rubenlopezg.wordpress.com/2014/05/07/que-es-y-como-funciona-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construyendo y entrenando la red neuronal\n",
    "\n",
    "Dado que solo necesitamos reconocer imágenes de letras y números individuales, no necesitamos una arquitectura de red neuronal muy compleja. Reconocer letras es un problema mucho más fácil que reconocer imágenes complejas como imágenes como gatos y perros.\n",
    "\n",
    "Utilizaremos una arquitectura de red neuronal convolucional simple con dos capas convolucionales y dos capas completamente conectadas:\n",
    "\n",
    "![title](img/cnn-architecture.png)\n",
    "\n",
    "## Prueba de buen entrenamiento vs mal entrenamiento\n",
    "\n",
    "Antes de utilizar la red neuronal convolucional completa, haremos algunos ejercicios para poder entender cual sería el resultado del proceso de aprendizaje de nuestra red neuronal convolucional, cuando tenga un buen entrenamiento vs un mal entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarde el mapeo de las etiquetas a codificaciones de un solo hot.\n",
    "# Necesitaremos esto más adelante cuando usemos el modelo para decodificar lo que significan sus predicciones\n",
    "with open(MODEL_LABELS_FILENAME, \"wb\") as f:\n",
    "    pickle.dump(lb, f)\n",
    "\n",
    "# ¡Construye la red neuronal!\n",
    "model = Sequential()\n",
    "\n",
    "# Primera capa convolucional con agrupación máxima\n",
    "model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(20, 20, 1), activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos creado nuestro primel modelo, en este escenario solamente tenemos la primera capa convolucional, veamos la forma en que esta capa transforma las imagenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the neural network to make a prediction\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(pred.shape)\n",
    "\n",
    "#For all the filters, plot the output of the input\n",
    "plt.figure(figsize=(18,18))\n",
    "filts = pred[0]\n",
    "for i in range(20):\n",
    "    filter_digit = filts[:,:,i]\n",
    "    plt.subplot(6,6,i+1)\n",
    "    plt.imshow(filter_digit,cmap='gray'); plt.axis('off');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarde el mapeo de las etiquetas a codificaciones de un solo hot.\n",
    "# Necesitaremos esto más adelante cuando usemos el modelo para decodificar lo que significan sus predicciones\n",
    "with open(MODEL_LABELS_FILENAME, \"wb\") as f:\n",
    "    pickle.dump(lb, f)\n",
    "\n",
    "# ¡Construye la red neuronal!\n",
    "model = Sequential()\n",
    "\n",
    "# Primera capa convolucional con agrupación máxima\n",
    "model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(20, 20, 1), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "#set weights for new model from weights trained on MNIST.\n",
    "for i in range(1):\n",
    "    model.layers[i].set_weights(model.layers[i].get_weights())\n",
    "\n",
    "# Ask the neural network to make a prediction\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(pred.shape)\n",
    "\n",
    "#For all the filters, plot the output of the input\n",
    "plt.figure(figsize=(18,18))\n",
    "filts = pred[0]\n",
    "for i in range(20):\n",
    "    filter_digit = filts[:,:,i]\n",
    "    plt.subplot(6,6,i+1)\n",
    "    plt.imshow(filter_digit,cmap='gray'); plt.axis('off');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarde el mapeo de las etiquetas a codificaciones de un solo hot.\n",
    "# Necesitaremos esto más adelante cuando usemos el modelo para decodificar lo que significan sus predicciones\n",
    "with open(MODEL_LABELS_FILENAME, \"wb\") as f:\n",
    "    pickle.dump(lb, f)\n",
    "\n",
    "# ¡Construye la red neuronal!\n",
    "model = Sequential()\n",
    "\n",
    "# Primera capa convolucional con agrupación máxima\n",
    "model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(20, 20, 1), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Segunda capa convolucional con agrupación máxima\n",
    "model.add(Conv2D(50, (5, 5), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "#set weights for new model from weights trained on MNIST.\n",
    "for i in range(1):\n",
    "    model.layers[i].set_weights(model.layers[i].get_weights())\n",
    "\n",
    "# Ask the neural network to make a prediction\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(pred.shape)\n",
    "\n",
    "#For all the filters, plot the output of the input\n",
    "plt.figure(figsize=(18,18))\n",
    "filts = pred[0]\n",
    "for i in range(20):\n",
    "    filter_digit = filts[:,:,i]\n",
    "    plt.subplot(6,6,i+1)\n",
    "    plt.imshow(filter_digit,cmap='gray'); plt.axis('off');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estas imagenes tenemos una idea de la forma en que la red neuronal convolucional procesa la información y empieza a aprender de los patrones de las imagenes desde diferentes aspectos. \n",
    "\n",
    "Volvamos al inicio y entrenemos nuestro modelo solamente utilizando la primera capa convolucional, a esta muestra llamaremos **Data de entrenamiento mala**\n",
    "\n",
    "Probaremos qué pasaría si entrenamos nuestra red neuronal convolucional con esta data, ¿cual es su potencial de descubrir las imagenes y el texto?\n",
    "\n",
    "![title](img/cnn-arch-bad.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarde el mapeo de las etiquetas a codificaciones de un solo hot.\n",
    "# Necesitaremos esto más adelante cuando usemos el modelo para decodificar lo que significan sus predicciones\n",
    "with open(\"bad_model.hdf5\", \"wb\") as f:\n",
    "    pickle.dump(lb, f)\n",
    "\n",
    "# ¡Construye la red neuronal!\n",
    "model = Sequential()\n",
    "\n",
    "# Primera capa convolucional con agrupación máxima\n",
    "model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(20, 20, 1), activation=\"relu\"))\n",
    "\n",
    "# Capa oculta con 500 nodos\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation=\"relu\"))\n",
    "\n",
    "# Capa de salida con 32 nodos (uno para cada posible letra / número que predecimos)\n",
    "model.add(Dense(32, activation=\"softmax\"))\n",
    "\n",
    "# Pídale a Keras que construya el modelo TensorFlow detrás de escena\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrena la red neuronal\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=32, epochs=1, verbose=1)\n",
    "\n",
    "# Guardar el modelo entrenado en el disco\n",
    "model.save(\"bad_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model(\"bad_model.hdf5\")\n",
    "\n",
    "with open(MODEL_LABELS_FILENAME, \"rb\") as f:\n",
    "    lb = pickle.load(f)\n",
    "\n",
    "# Bad DATA:  1269, 719 3042 1175\n",
    "num = 3042 #random.randint(1,9686)\n",
    "image = X_test[num][:, :, 0]\n",
    "image2 = X_test[num]\n",
    "\n",
    "prediction = model.predict(image2.reshape(1,20,20,1))\n",
    "    \n",
    "print('Image Number: ' + str(num))\n",
    "\n",
    "letter = lb.inverse_transform(prediction)[0]\n",
    "\n",
    "print(letter)\n",
    "\n",
    "plt.figure(figsize=(15,4));\n",
    "plt.subplot(1,2,1);\n",
    "plt.title('Example of digit: {}'.format(letter));\n",
    "plt.imshow(image,cmap='gray'); plt.axis('off');\n",
    "probs = model.predict_proba(image2.reshape(1,20,20,1),batch_size=1)\n",
    "plt.subplot(1,2,2);\n",
    "plt.title('Probabilities for each digit class');\n",
    "plt.bar(np.arange(32),probs.reshape(32),align='center'); \n",
    "plt.xticks(np.arange(32),('2','3','4','5','6','7','8','9','A','B','C','D','E','F','G','H','J','K','L','M','N','P','Q','R','S','T','U','V','W','X','Y','Z'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Guarde el mapeo de las etiquetas a codificaciones de un solo hot.\n",
    "# Necesitaremos esto más adelante cuando usemos el modelo para decodificar lo que significan sus predicciones\n",
    "with open(MODEL_LABELS_FILENAME, \"wb\") as f:\n",
    "    pickle.dump(lb, f)\n",
    "\n",
    "# ¡Construye la red neuronal!\n",
    "model = Sequential()\n",
    "\n",
    "# Primera capa convolucional con agrupación máxima\n",
    "model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(20, 20, 1), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Segunda capa convolucional con agrupación máxima\n",
    "model.add(Conv2D(50, (5, 5), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Capa oculta con 500 nodos\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation=\"relu\"))\n",
    "\n",
    "# Capa de salida con 32 nodos (uno para cada posible letra / número que predecimos)\n",
    "model.add(Dense(32, activation=\"softmax\"))\n",
    "\n",
    "# Pídale a Keras que construya el modelo TensorFlow detrás de escena\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrena la red neuronal\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=32, epochs=10, verbose=1)\n",
    "\n",
    "# Epoch - https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9\n",
    "\n",
    "# Guardar el modelo entrenado en el disco\n",
    "model.save(MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model(MODEL_FILENAME)\n",
    "\n",
    "with open(MODEL_LABELS_FILENAME, \"rb\") as f:\n",
    "    lb = pickle.load(f)\n",
    "\n",
    "\n",
    "num = 3042 #,5940,2433,5936,9005\n",
    "image = X_test[num][:, :, 0]\n",
    "image2 = X_test[num]\n",
    "\n",
    "prediction = model.predict(image2.reshape(1,20,20,1))\n",
    "    \n",
    "print(image.shape)\n",
    "\n",
    "letter = lb.inverse_transform(prediction)[0]\n",
    "\n",
    "print(letter)\n",
    "\n",
    "plt.figure(figsize=(15,4));\n",
    "plt.subplot(1,2,1);\n",
    "plt.title('Example of digit: {}'.format(letter));\n",
    "plt.imshow(image,cmap='gray'); plt.axis('off');\n",
    "probs = model.predict_proba(image2.reshape(1,20,20,1),batch_size=1)\n",
    "plt.subplot(1,2,2);\n",
    "plt.title('Probabilities for each digit class');\n",
    "plt.bar(np.arange(32),probs.reshape(32),align='center'); \n",
    "plt.xticks(np.arange(32),('2','3','4','5','6','7','8','9','A','B','C','D','E','F','G','H','J','K','L','M','N','P','Q','R','S','T','U','V','W','X','Y','Z'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
