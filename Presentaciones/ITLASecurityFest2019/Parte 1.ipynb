{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # ITLA Security Fest \n",
    "# # Pentesting Utilizando Inteligencia Artificial \n",
    "\n",
    "El objetivo de este taller es aplicar el uso de la inteligencia artificial (Deep Learning) para resolver captchas y poder automatizar la enumeración o explotación de servicios que tengan este control de seguridad. \n",
    "\n",
    "Esta presentación está basada en la investigación realizada por \n",
    "Adam Geitgey https://medium.com/@ageitgey/how-to-break-a-captcha-system-in-15-minutes-with-machine-learning-dbebb035a710\n",
    "\n",
    "Este ejercicio nos permitirá resolver los captchas utilizando Deep Learning. \n",
    "\n",
    "# Introducción\n",
    "\n",
    "El método que utilizaremos aplica para la resolver el captcha del componente \"Really Simple CAPTCHA\", un pluging de wordpress que es utilizado en más de un millon de paginas web. \n",
    "\n",
    "**Nota**: Si bien es cierto que el metodo puede ser utilizado para resolver otros captchas, solamente ha sido probado para resolver imagenes de este pluging y posiblemente necesite adecuaciones para resolver otros captchas.  \n",
    "\n",
    "Para poder utilizar Deep Learning necesitaremos completar el siguiente proceso:\n",
    "\n",
    "**1. Extraer cada letra/número de las imagenes del repositorio \"Really Simple CAPTCHA\"**, guardarlas para entrenar nuestro modelo.Cada imagen tiene 4 letras y/o números:\n",
    "\n",
    "**2. Entrenar el modelo utilizando las imagenes individuales.**\n",
    "\n",
    "**3. Utilizar el modelo para resolver captchas.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. - Extraer las Imagenes\n",
    "\n",
    "Para entrenar nuestro modelo de deep learning, necesitamos enseñarle cómo se ve un número (1-9) y cómo se ven las letras del alfabeto (A-Z). Excluiremos el 0 y la i, ya que el programa de Really Simple Captcha no las utiliza, para evitar confusiones.\n",
    "\n",
    "Haremos el ejercicio con una imagen para explicar el concepto y luego verificaremos todas las imagenes. \n",
    "\n",
    "![title](img/demo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaremos los siguientes módulos:\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "\n",
    "# Estos modulos nos dan acceso a un grupo de funciones que nos permitirán trabajar con imagenes:\n",
    "# Visualizarlas, leerlas, guardarlas, rotarlas, cambiar su tamaño y colores, etc.\n",
    "import imutils\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "CAPTCHA_IMAGE = \"generated_captcha_images/2A2X.png\"\n",
    "OUTPUT_FOLDER = \"extracted_letter_images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que el nombre del archivo contiene el texto del captcha (es decir, \"2A2X.png\" tiene el texto \"2A2X\"),\n",
    "# Tomemos el nombre del archivo base como el texto\n",
    "filename = os.path.basename(CAPTCHA_IMAGE)\n",
    "captcha_correct_text = os.path.splitext(filename)[0]\n",
    "\n",
    "print(filename)\n",
    "print(captcha_correct_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargue la imagen y conviértala a escala de grises\n",
    "image = cv2.imread(CAPTCHA_IMAGE)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Genera una nueva figura\n",
    "plt.figure()\n",
    "\n",
    "# Mostrar la primera imagen en la columna izquierda\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image, cmap = plt.cm.binary)\n",
    "plt.title('original')\n",
    "\n",
    "# Desactivar numeración de ejes\n",
    "plt.axis('off')\n",
    "\n",
    "# Mostrar la segunda imagen en la columna derecha\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(gray, cmap = plt.cm.binary)\n",
    "plt.title('gray')\n",
    "\n",
    "# Active la numeración del eje\n",
    "plt.axis('on')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregue un poco de relleno adicional alrededor de la imagen\n",
    "gray = cv2.copyMakeBorder(gray, 8, 8, 8, 8, cv2.BORDER_REPLICATE)\n",
    "\n",
    "plt.imshow(gray, cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umbral de la imagen (convertirla a blanco y negro puro)\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "plt.imshow(thresh, cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encontrar los contornos (manchas continuas de píxeles) de la imagen\n",
    "contours = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Hack para compatibilidad con diferentes versiones de OpenCV\n",
    "contours = contours[1] if imutils.is_cv3() else contours[0]\n",
    "print(\"Numero de contornos = \" + str(len(contours)))\n",
    "\n",
    "# Ejemplo de Contorno:\n",
    "img = gray.copy()\n",
    "cv2.drawContours(img, contours, -1, (0,255,0), 3)\n",
    "plt.imshow(img, cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable para guardar las letras \n",
    "letter_image_regions = []\n",
    "\n",
    "# Ahora podemos recorrer cada uno de los cuatro contornos y extraer la letra\n",
    "# dentro de cada uno\n",
    "for contour in contours:\n",
    "    # Obtener el rectángulo que contiene el contorno\n",
    "    (x, y, w, h) = cv2.boundingRect(contour)\n",
    "\n",
    "    # Compare el ancho y la altura del contorno para detectar letras que\n",
    "    # están unidos en alguna parte\n",
    "    if w / h > 1.25:\n",
    "        # ¡Este contorno es demasiado ancho para ser una sola letra!\n",
    "        # ¡Divídelo por la mitad en regiones de dos letras!\n",
    "        half_width = int(w / 2)\n",
    "        letter_image_regions.append((x, y, half_width, h))\n",
    "        letter_image_regions.append((x + half_width, y, half_width, h))\n",
    "    else:\n",
    "        # Esta es una letra normal en sí misma\n",
    "        letter_image_regions.append((x, y, w, h))\n",
    "\n",
    "print(letter_image_regions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "# Guardar cada letra como una sola imagen\n",
    "for letter_bounding_box, letter_text in zip(letter_image_regions, captcha_correct_text):\n",
    "    # Toma las coordenadas de la letra en la imagen\n",
    "    x, y, w, h = letter_bounding_box\n",
    "\n",
    "    # Extraer la letra de la imagen original con un margen de 2 píxeles alrededor del borde\n",
    "    letter_image = thresh[y - 2:y + h + 2, x - 2:x + w + 2]\n",
    "\n",
    "    # Agrupar las imagenes para mostrarlas una por una. \n",
    "    plt.figure(count)\n",
    "    plt.imshow(letter_image, cmap = plt.cm.binary)\n",
    "    count = count + 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
